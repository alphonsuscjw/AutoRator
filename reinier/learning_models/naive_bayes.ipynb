{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "                review_id                                               text  \\\n0  fj7N9Lp6AvEEy6LHrDZzjw  When I was shown to my seat of was still wet s...   \n1  YX2cFHDxlUfGnQ8bHPq4cA  Not Impressed at all. Ordered a omelette and b...   \n2  pDN3hRBarmGWXbK64A83MA  never coming back here again. all of the glass...   \n3  ae5On6KCPiglMQJ--1JcTQ  I don't recommend this place for breakfast. Th...   \n4  i5jMeyoJSbUrQ7T-AU22_A  Well, lots to say. Managers were busy makin co...   \n\n   stars  positive  neutral  negative  compound_sentiment  newstar  anger  \\\n0      2     0.036    0.846     0.118             -0.6437        1    0.0   \n1      1     0.078    0.715     0.207             -0.8337        1    0.0   \n2      1     0.065    0.865     0.070             -0.3773        1    0.0   \n3      2     0.000    0.860     0.140             -0.7672        1    0.0   \n4      1     0.124    0.741     0.134             -0.3129        1    2.0   \n\n   anticipation  disgust  fear  joy  negative.1  positive.1  sadness  \\\n0           1.0      0.0   0.0  0.0         1.0         2.0      1.0   \n1           1.0      1.0   1.0  1.0         3.0         2.0      3.0   \n2           1.0      3.0   1.0  1.0         7.0         2.0      2.0   \n3           1.0      0.0   0.0  3.0         3.0         6.0      0.0   \n4           4.0      2.0   1.0  1.0         4.0         3.0      1.0   \n\n   surprise  trust  word_count  \n0       0.0    1.0        26.0  \n1       0.0    1.0        33.0  \n2       0.0    1.0        64.0  \n3       1.0    3.0        23.0  \n4       0.0    1.0        60.0  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>review_id</th>\n      <th>text</th>\n      <th>stars</th>\n      <th>positive</th>\n      <th>neutral</th>\n      <th>negative</th>\n      <th>compound_sentiment</th>\n      <th>newstar</th>\n      <th>anger</th>\n      <th>anticipation</th>\n      <th>disgust</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>negative.1</th>\n      <th>positive.1</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>trust</th>\n      <th>word_count</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>fj7N9Lp6AvEEy6LHrDZzjw</td>\n      <td>When I was shown to my seat of was still wet s...</td>\n      <td>2</td>\n      <td>0.036</td>\n      <td>0.846</td>\n      <td>0.118</td>\n      <td>-0.6437</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>26.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>YX2cFHDxlUfGnQ8bHPq4cA</td>\n      <td>Not Impressed at all. Ordered a omelette and b...</td>\n      <td>1</td>\n      <td>0.078</td>\n      <td>0.715</td>\n      <td>0.207</td>\n      <td>-0.8337</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>33.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>pDN3hRBarmGWXbK64A83MA</td>\n      <td>never coming back here again. all of the glass...</td>\n      <td>1</td>\n      <td>0.065</td>\n      <td>0.865</td>\n      <td>0.070</td>\n      <td>-0.3773</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>7.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>64.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>ae5On6KCPiglMQJ--1JcTQ</td>\n      <td>I don't recommend this place for breakfast. Th...</td>\n      <td>2</td>\n      <td>0.000</td>\n      <td>0.860</td>\n      <td>0.140</td>\n      <td>-0.7672</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>3.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>23.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>i5jMeyoJSbUrQ7T-AU22_A</td>\n      <td>Well, lots to say. Managers were busy makin co...</td>\n      <td>1</td>\n      <td>0.124</td>\n      <td>0.741</td>\n      <td>0.134</td>\n      <td>-0.3129</td>\n      <td>1</td>\n      <td>2.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>3.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>60.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.metrics import accuracy_score\n",
    "df = pd.read_csv('data/vader_emolex_rest.csv')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6306496374652182\n"
     ]
    }
   ],
   "source": [
    "# Preprocess the text data\n",
    "vectorizer = CountVectorizer()\n",
    "X = vectorizer.fit_transform(df['text'])\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, df['stars'], train_size=0.6, random_state=42)\n",
    "# Train the naive Bayes model\n",
    "model = MultinomialNB()\n",
    "model.fit(X_train, y_train)\n",
    "# Make predictions on the test set\n",
    "y_pred = model.predict(X_test)\n",
    "# Evaluate the accuracy of the model\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   newstar                                               text\n0        1  When I was shown to my seat of was still wet s...\n1        1  Not Impressed at all. Ordered a omelette and b...\n2        1  never coming back here again. all of the glass...\n3        1  I don't recommend this place for breakfast. Th...\n4        1  Well, lots to say. Managers were busy makin co...",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>newstar</th>\n      <th>text</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>When I was shown to my seat of was still wet s...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Not Impressed at all. Ordered a omelette and b...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>never coming back here again. all of the glass...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>I don't recommend this place for breakfast. Th...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Well, lots to say. Managers were busy makin co...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = df[[\"newstar\",\"text\"]]\n",
    "# df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "   newstar                                               text  positive\n0        1  When I was shown to my seat of was still wet s...         0\n1        1  Not Impressed at all. Ordered a omelette and b...         0\n2        1  never coming back here again. all of the glass...         0\n3        1  I don't recommend this place for breakfast. Th...         0\n4        1  Well, lots to say. Managers were busy makin co...         0",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>newstar</th>\n      <th>text</th>\n      <th>positive</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>When I was shown to my seat of was still wet s...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Not Impressed at all. Ordered a omelette and b...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1</td>\n      <td>never coming back here again. all of the glass...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1</td>\n      <td>I don't recommend this place for breakfast. Th...</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1</td>\n      <td>Well, lots to say. Managers were busy makin co...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positive = []\n",
    "for star in df[\"star\"]:\n",
    "    if star >= 3:\n",
    "        positive.append(1)\n",
    "    else:\n",
    "        positive.append(0)\n",
    "df[\"positive\"] = positive\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m review \u001B[38;5;241m=\u001B[39m review\u001B[38;5;241m.\u001B[39msplit()\n\u001B[1;32m     10\u001B[0m ps \u001B[38;5;241m=\u001B[39m PorterStemmer()\n\u001B[0;32m---> 11\u001B[0m review \u001B[38;5;241m=\u001B[39m [ps\u001B[38;5;241m.\u001B[39mstem(word) \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m review \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mset\u001B[39m(stopwords\u001B[38;5;241m.\u001B[39mwords(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124menglish\u001B[39m\u001B[38;5;124m'\u001B[39m))]\n\u001B[1;32m     12\u001B[0m review \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(review)\n\u001B[1;32m     13\u001B[0m corpus\u001B[38;5;241m.\u001B[39mappend(review)\n",
      "Cell \u001B[0;32mIn[7], line 11\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m      9\u001B[0m review \u001B[38;5;241m=\u001B[39m review\u001B[38;5;241m.\u001B[39msplit()\n\u001B[1;32m     10\u001B[0m ps \u001B[38;5;241m=\u001B[39m PorterStemmer()\n\u001B[0;32m---> 11\u001B[0m review \u001B[38;5;241m=\u001B[39m [ps\u001B[38;5;241m.\u001B[39mstem(word) \u001B[38;5;28;01mfor\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m review \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m word \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mset\u001B[39m(\u001B[43mstopwords\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mwords\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43menglish\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m)]\n\u001B[1;32m     12\u001B[0m review \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(review)\n\u001B[1;32m     13\u001B[0m corpus\u001B[38;5;241m.\u001B[39mappend(review)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/nltk/corpus/reader/wordlist.py:21\u001B[0m, in \u001B[0;36mWordListCorpusReader.words\u001B[0;34m(self, fileids, ignore_lines_startswith)\u001B[0m\n\u001B[1;32m     18\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mwords\u001B[39m(\u001B[38;5;28mself\u001B[39m, fileids\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mNone\u001B[39;00m, ignore_lines_startswith\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m):\n\u001B[1;32m     19\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\n\u001B[1;32m     20\u001B[0m         line\n\u001B[0;32m---> 21\u001B[0m         \u001B[38;5;28;01mfor\u001B[39;00m line \u001B[38;5;129;01min\u001B[39;00m \u001B[43mline_tokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mraw\u001B[49m\u001B[43m(\u001B[49m\u001B[43mfileids\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     22\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m line\u001B[38;5;241m.\u001B[39mstartswith(ignore_lines_startswith)\n\u001B[1;32m     23\u001B[0m     ]\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/nltk/tokenize/simple.py:137\u001B[0m, in \u001B[0;36mline_tokenize\u001B[0;34m(text, blanklines)\u001B[0m\n\u001B[1;32m    136\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mline_tokenize\u001B[39m(text, blanklines\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiscard\u001B[39m\u001B[38;5;124m\"\u001B[39m):\n\u001B[0;32m--> 137\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mLineTokenizer\u001B[49m\u001B[43m(\u001B[49m\u001B[43mblanklines\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtokenize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/nltk/tokenize/simple.py:116\u001B[0m, in \u001B[0;36mLineTokenizer.tokenize\u001B[0;34m(self, s)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;66;03m# If requested, strip off blank lines.\u001B[39;00m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_blanklines \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiscard\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 116\u001B[0m     lines \u001B[38;5;241m=\u001B[39m [l \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lines \u001B[38;5;28;01mif\u001B[39;00m l\u001B[38;5;241m.\u001B[39mrstrip()]\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_blanklines \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiscard-eof\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m lines \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m lines[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mstrip():\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/nltk/tokenize/simple.py:116\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    114\u001B[0m \u001B[38;5;66;03m# If requested, strip off blank lines.\u001B[39;00m\n\u001B[1;32m    115\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_blanklines \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiscard\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m--> 116\u001B[0m     lines \u001B[38;5;241m=\u001B[39m [l \u001B[38;5;28;01mfor\u001B[39;00m l \u001B[38;5;129;01min\u001B[39;00m lines \u001B[38;5;28;01mif\u001B[39;00m l\u001B[38;5;241m.\u001B[39mrstrip()]\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01melif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_blanklines \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mdiscard-eof\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m lines \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m lines[\u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m]\u001B[38;5;241m.\u001B[39mstrip():\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "for i in range(0, len(df)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = df.iloc[0:len(df), 2].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=2, \n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 7251  2870]\n",
      " [ 2239 12640]]\n",
      "\n",
      "\n",
      "Accuracy is  0.8\n"
     ]
    }
   ],
   "source": [
    "# Multinomial NB\n",
    "\n",
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB(alpha=0.1)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix:\\n\",cm)\n",
    "\n",
    "# Accuracy, Precision and Recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score1 = accuracy_score(y_test,y_pred)\n",
    "# score2 = precision_score(y_test,y_pred)\n",
    "# score3= recall_score(y_test,y_pred)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy is \",round(score1,2))\n",
    "# print(\"Precision is \",round(score2,2))\n",
    "# print(\"Recall is \",round(score3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[ 853  158]\n",
      " [ 474 1015]]\n",
      "\n",
      "\n",
      "Accuracy Bernoulli is  0.75\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli NB\n",
    "\n",
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "classifier = BernoulliNB(alpha=0.8)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Making the Confusion Matrix\n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm = confusion_matrix(y_test, y_pred)\n",
    "print (\"Confusion Matrix:\\n\",cm)\n",
    "\n",
    "# Accuracy, Precision and Recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score1 = accuracy_score(y_test,y_pred)\n",
    "# score2 = precision_score(y_test,y_pred)\n",
    "# score3= recall_score(y_test,y_pred)\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy Bernoulli is \",round(score1,2))\n",
    "# print(\"Precision is \",round(score2,2))\n",
    "# print(\"Recall is \",round(score3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
