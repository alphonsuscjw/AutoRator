{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>review_id</th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "      <th>positive</th>\n",
       "      <th>neutral</th>\n",
       "      <th>negative</th>\n",
       "      <th>compound_sentiment</th>\n",
       "      <th>newstar</th>\n",
       "      <th>anger</th>\n",
       "      <th>anticipation</th>\n",
       "      <th>disgust</th>\n",
       "      <th>fear</th>\n",
       "      <th>joy</th>\n",
       "      <th>negative.1</th>\n",
       "      <th>positive.1</th>\n",
       "      <th>sadness</th>\n",
       "      <th>surprise</th>\n",
       "      <th>trust</th>\n",
       "      <th>word_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>fj7N9Lp6AvEEy6LHrDZzjw</td>\n",
       "      <td>When I was shown to my seat of was still wet s...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.846</td>\n",
       "      <td>0.118</td>\n",
       "      <td>-0.6437</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>YX2cFHDxlUfGnQ8bHPq4cA</td>\n",
       "      <td>Not Impressed at all. Ordered a omelette and b...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.078</td>\n",
       "      <td>0.715</td>\n",
       "      <td>0.207</td>\n",
       "      <td>-0.8337</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>pDN3hRBarmGWXbK64A83MA</td>\n",
       "      <td>never coming back here again. all of the glass...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.065</td>\n",
       "      <td>0.865</td>\n",
       "      <td>0.070</td>\n",
       "      <td>-0.3773</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>ae5On6KCPiglMQJ--1JcTQ</td>\n",
       "      <td>I don't recommend this place for breakfast. Th...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.860</td>\n",
       "      <td>0.140</td>\n",
       "      <td>-0.7672</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>i5jMeyoJSbUrQ7T-AU22_A</td>\n",
       "      <td>Well, lots to say. Managers were busy makin co...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.124</td>\n",
       "      <td>0.741</td>\n",
       "      <td>0.134</td>\n",
       "      <td>-0.3129</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>60.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0               review_id  \\\n",
       "0           0  fj7N9Lp6AvEEy6LHrDZzjw   \n",
       "1           1  YX2cFHDxlUfGnQ8bHPq4cA   \n",
       "2           2  pDN3hRBarmGWXbK64A83MA   \n",
       "3           3  ae5On6KCPiglMQJ--1JcTQ   \n",
       "4           4  i5jMeyoJSbUrQ7T-AU22_A   \n",
       "\n",
       "                                                text  stars  positive  \\\n",
       "0  When I was shown to my seat of was still wet s...      2     0.036   \n",
       "1  Not Impressed at all. Ordered a omelette and b...      1     0.078   \n",
       "2  never coming back here again. all of the glass...      1     0.065   \n",
       "3  I don't recommend this place for breakfast. Th...      2     0.000   \n",
       "4  Well, lots to say. Managers were busy makin co...      1     0.124   \n",
       "\n",
       "   neutral  negative  compound_sentiment  newstar  anger  anticipation  \\\n",
       "0    0.846     0.118             -0.6437        1    0.0           1.0   \n",
       "1    0.715     0.207             -0.8337        1    0.0           1.0   \n",
       "2    0.865     0.070             -0.3773        1    0.0           1.0   \n",
       "3    0.860     0.140             -0.7672        1    0.0           1.0   \n",
       "4    0.741     0.134             -0.3129        1    2.0           4.0   \n",
       "\n",
       "   disgust  fear  joy  negative.1  positive.1  sadness  surprise  trust  \\\n",
       "0      0.0   0.0  0.0         1.0         2.0      1.0       0.0    1.0   \n",
       "1      1.0   1.0  1.0         3.0         2.0      3.0       0.0    1.0   \n",
       "2      3.0   1.0  1.0         7.0         2.0      2.0       0.0    1.0   \n",
       "3      0.0   0.0  3.0         3.0         6.0      0.0       1.0    3.0   \n",
       "4      2.0   1.0  1.0         4.0         3.0      1.0       0.0    1.0   \n",
       "\n",
       "   word_count  \n",
       "0        26.0  \n",
       "1        33.0  \n",
       "2        64.0  \n",
       "3        23.0  \n",
       "4        60.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "data = Path('../data/subset_2000.csv')\n",
    "df = pd.read_csv(data)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>stars</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>When I was shown to my seat of was still wet s...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Impressed at all. Ordered a omelette and b...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>never coming back here again. all of the glass...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I don't recommend this place for breakfast. Th...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Well, lots to say. Managers were busy makin co...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  stars\n",
       "0  When I was shown to my seat of was still wet s...      2\n",
       "1  Not Impressed at all. Ordered a omelette and b...      1\n",
       "2  never coming back here again. all of the glass...      1\n",
       "3  I don't recommend this place for breakfast. Th...      2\n",
       "4  Well, lots to say. Managers were busy makin co...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = df.loc[:,[\"text\",\"stars\"]]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "corpus = []\n",
    "for i in range(0, len(df)):\n",
    "    review = re.sub('[^a-zA-Z]', ' ', df['text'][i])\n",
    "    review = review.lower()\n",
    "    review = review.split()\n",
    "    ps = PorterStemmer()\n",
    "    review = [ps.stem(word) for word in review if not word in set(stopwords.words('english'))]\n",
    "    review = ' '.join(review)\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(max_features = 1500)\n",
    "X = cv.fit_transform(corpus).toarray()\n",
    "y = df.iloc[:, 1].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_categorical = []\n",
    "for star in y:\n",
    "    if star == 5 or star == 4:\n",
    "        y_categorical.append(\"positive\")\n",
    "    elif star == 3:\n",
    "        y_categorical.append(\"neutral\")\n",
    "    elif star == 2 or star == 1:\n",
    "        y_categorical.append(\"negative\")\n",
    "y = y_categorical"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into the Training set and Test set\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, \n",
    "                                                    y, \n",
    "                                                    random_state=2, \n",
    "                                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.78      0.73      0.75       849\n",
      "     neutral       0.36      0.45      0.40       371\n",
      "    positive       0.88      0.86      0.87      1280\n",
      "\n",
      "    accuracy                           0.75      2500\n",
      "   macro avg       0.67      0.68      0.67      2500\n",
      "weighted avg       0.77      0.75      0.76      2500\n",
      "\n",
      "\n",
      "\n",
      "Accuracy is  0.75\n",
      "Precision is  0.77\n",
      "Recall is  0.75\n"
     ]
    }
   ],
   "source": [
    "# Multinomial NB\n",
    "\n",
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "classifier = MultinomialNB(alpha=0.1)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Create and save the testing classification report\n",
    "from sklearn.metrics import classification_report\n",
    "testing_report = classification_report(y_test, y_pred)\n",
    "# Print the testing classification report\n",
    "print(testing_report)\n",
    "\n",
    "# Accuracy, Precision and Recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score1 = accuracy_score(y_test,y_pred)\n",
    "score2 = precision_score(y_test,y_pred, average=\"weighted\")\n",
    "score3= recall_score(y_test,y_pred, average=\"weighted\")\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy is \",round(score1,2))\n",
    "print(\"Precision is \",round(score2,2))\n",
    "print(\"Recall is \",round(score3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.79      0.65      0.72       849\n",
      "     neutral       0.34      0.38      0.36       371\n",
      "    positive       0.81      0.87      0.84      1280\n",
      "\n",
      "    accuracy                           0.73      2500\n",
      "   macro avg       0.65      0.64      0.64      2500\n",
      "weighted avg       0.73      0.73      0.73      2500\n",
      "\n",
      "\n",
      "\n",
      "Accuracy is  0.73\n",
      "Precision is  0.73\n",
      "Recall is  0.73\n"
     ]
    }
   ],
   "source": [
    "# Bernoulli NB\n",
    "\n",
    "# Fitting Naive Bayes to the Training set\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "classifier = BernoulliNB(alpha=0.8)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Create and save the testing classification report\n",
    "from sklearn.metrics import classification_report\n",
    "testing_report = classification_report(y_test, y_pred)\n",
    "# Print the testing classification report\n",
    "print(testing_report)\n",
    "\n",
    "# Accuracy, Precision and Recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score1 = accuracy_score(y_test,y_pred)\n",
    "score2 = precision_score(y_test,y_pred, average=\"weighted\")\n",
    "score3= recall_score(y_test,y_pred, average=\"weighted\")\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy is \",round(score1,2))\n",
    "print(\"Precision is \",round(score2,2))\n",
    "print(\"Recall is \",round(score3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    negative       0.77      0.74      0.75       849\n",
      "     neutral       0.36      0.33      0.34       371\n",
      "    positive       0.85      0.89      0.87      1280\n",
      "\n",
      "    accuracy                           0.76      2500\n",
      "   macro avg       0.66      0.65      0.66      2500\n",
      "weighted avg       0.75      0.76      0.75      2500\n",
      "\n",
      "\n",
      "\n",
      "Accuracy is  0.76\n",
      "Precision is  0.75\n",
      "Recall is  0.76\n"
     ]
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "# Fitting Logistic Regression to the Training set\n",
    "from sklearn import linear_model\n",
    "classifier = linear_model.LogisticRegression(max_iter=2000)\n",
    "classifier.fit(X_train, y_train)\n",
    "\n",
    "# Predicting the Test set results\n",
    "y_pred = classifier.predict(X_test)\n",
    "\n",
    "# Create and save the testing classification report\n",
    "from sklearn.metrics import classification_report\n",
    "testing_report = classification_report(y_test, y_pred)\n",
    "# Print the testing classification report\n",
    "print(testing_report)\n",
    "\n",
    "# Accuracy, Precision and Recall\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "score1 = accuracy_score(y_test,y_pred)\n",
    "score2 = precision_score(y_test,y_pred, average=\"weighted\")\n",
    "score3= recall_score(y_test,y_pred, average=\"weighted\")\n",
    "print(\"\\n\")\n",
    "print(\"Accuracy is \",round(score1,2))\n",
    "print(\"Precision is \",round(score2,2))\n",
    "print(\"Recall is \",round(score3,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
