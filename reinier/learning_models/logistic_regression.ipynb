{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = Path('data/vader_emolex.csv')\n",
    "df = pd.read_csv(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "outputs": [],
   "source": [
    "bins = [0, 2.5, 3.5, 5]\n",
    "labels = ['Negative', 'Neutral', 'Positive']\n",
    "df['bins'] = pd.cut(df['stars'], bins=bins, labels=labels)\n",
    "n = 50000\n",
    "subset = df.groupby('bins').head(n)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "subset.set_index('review_id', inplace=True)\n",
    "df = subset.drop(columns=['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "outputs": [
    {
     "data": {
      "text/plain": "                        stars  compound_sentiment  positive  neutral  \\\nreview_id                                                              \nzurS64w23RAXHPToR0C39Q      4              0.9906     0.195    0.779   \n1hAS--WgusxuLwhHND12qw      5              0.9882     0.360    0.640   \n3NwwrhNzJ6H1P-5vbsvyMQ      5              0.9723     0.177    0.787   \nbHCNw775nDiJXQGxERp5VQ      5              0.9979     0.163    0.810   \nkc1aIPCo1I4E_17KuIkY5Q      2             -0.7723     0.091    0.796   \n\n                        negative  anger  anticipation  disgust  fear  joy  \\\nreview_id                                                                   \nzurS64w23RAXHPToR0C39Q     0.026    0.0           8.0      1.0   3.0  8.0   \n1hAS--WgusxuLwhHND12qw     0.000    0.0           2.0      0.0   0.0  5.0   \n3NwwrhNzJ6H1P-5vbsvyMQ     0.036    0.0           3.0      0.0   1.0  6.0   \nbHCNw775nDiJXQGxERp5VQ     0.027    1.0           6.0      1.0   3.0  9.0   \nkc1aIPCo1I4E_17KuIkY5Q     0.113    2.0           2.0      2.0   3.0  5.0   \n\n                        negative.1  positive.1  sadness  surprise  trust  \\\nreview_id                                                                  \nzurS64w23RAXHPToR0C39Q         0.0        14.0      1.0       8.0    9.0   \n1hAS--WgusxuLwhHND12qw         0.0         6.0      1.0       1.0    2.0   \n3NwwrhNzJ6H1P-5vbsvyMQ         2.0         8.0      0.0       1.0    2.0   \nbHCNw775nDiJXQGxERp5VQ         6.0        20.0      1.0       4.0    8.0   \nkc1aIPCo1I4E_17KuIkY5Q         3.0         9.0      2.0       1.0    4.0   \n\n                        word_count      bins  \nreview_id                                     \nzurS64w23RAXHPToR0C39Q       123.0  Positive  \n1hAS--WgusxuLwhHND12qw        33.0  Positive  \n3NwwrhNzJ6H1P-5vbsvyMQ        63.0  Positive  \nbHCNw775nDiJXQGxERp5VQ       231.0  Positive  \nkc1aIPCo1I4E_17KuIkY5Q       101.0  Negative  ",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>stars</th>\n      <th>compound_sentiment</th>\n      <th>positive</th>\n      <th>neutral</th>\n      <th>negative</th>\n      <th>anger</th>\n      <th>anticipation</th>\n      <th>disgust</th>\n      <th>fear</th>\n      <th>joy</th>\n      <th>negative.1</th>\n      <th>positive.1</th>\n      <th>sadness</th>\n      <th>surprise</th>\n      <th>trust</th>\n      <th>word_count</th>\n      <th>bins</th>\n    </tr>\n    <tr>\n      <th>review_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>zurS64w23RAXHPToR0C39Q</th>\n      <td>4</td>\n      <td>0.9906</td>\n      <td>0.195</td>\n      <td>0.779</td>\n      <td>0.026</td>\n      <td>0.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>14.0</td>\n      <td>1.0</td>\n      <td>8.0</td>\n      <td>9.0</td>\n      <td>123.0</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>1hAS--WgusxuLwhHND12qw</th>\n      <td>5</td>\n      <td>0.9882</td>\n      <td>0.360</td>\n      <td>0.640</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>33.0</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>3NwwrhNzJ6H1P-5vbsvyMQ</th>\n      <td>5</td>\n      <td>0.9723</td>\n      <td>0.177</td>\n      <td>0.787</td>\n      <td>0.036</td>\n      <td>0.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>63.0</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>bHCNw775nDiJXQGxERp5VQ</th>\n      <td>5</td>\n      <td>0.9979</td>\n      <td>0.163</td>\n      <td>0.810</td>\n      <td>0.027</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>1.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>6.0</td>\n      <td>20.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>8.0</td>\n      <td>231.0</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>kc1aIPCo1I4E_17KuIkY5Q</th>\n      <td>2</td>\n      <td>-0.7723</td>\n      <td>0.091</td>\n      <td>0.796</td>\n      <td>0.113</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>9.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>101.0</td>\n      <td>Negative</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "(56250, 16)"
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = df.sample(frac=0.5, random_state=1)\n",
    "y = test[\"bins\"]\n",
    "X = test.drop(columns=[\"bins\"])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)\n",
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "X_scaler = scaler.fit(X_train)\n",
    "X_train = X_scaler.transform(X_train)\n",
    "X_test = X_scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegression(max_iter=30000, random_state=1)",
      "text/html": "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression(max_iter=30000, random_state=1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" checked><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression(max_iter=30000, random_state=1)</pre></div></div></div></div></div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "classifier = LogisticRegression(solver='lbfgs',max_iter=30000,random_state=1)\n",
    "classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_model = classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Data Score: 1.0\n",
      "Testing Data Score: 1.0\n"
     ]
    }
   ],
   "source": [
    "print(f\"Training Data Score: {classifier.score(X_train, y_train)}\")\n",
    "print(f\"Testing Data Score: {classifier.score(X_test, y_test)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Generate training predictions\n",
    "training_predictions = lr_model.predict(X_train)\n",
    "testing_predictions = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00     18783\n",
      "     Neutral       1.00      1.00      1.00     18787\n",
      "    Positive       1.00      1.00      1.00     18680\n",
      "\n",
      "    accuracy                           1.00     56250\n",
      "   macro avg       1.00      1.00      1.00     56250\n",
      "weighted avg       1.00      1.00      1.00     56250\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "training_report = classification_report(y_train, training_predictions)\n",
    "print(training_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    Negative       1.00      1.00      1.00      6211\n",
      "     Neutral       1.00      1.00      1.00      6289\n",
      "    Positive       1.00      1.00      1.00      6250\n",
      "\n",
      "    accuracy                           1.00     18750\n",
      "   macro avg       1.00      1.00      1.00     18750\n",
      "weighted avg       1.00      1.00      1.00     18750\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Create and save the testing classification report\n",
    "testing_report = classification_report(y_test, testing_predictions)\n",
    "print(testing_report)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [
    {
     "data": {
      "text/plain": "['model_ls.joblib']"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "dump(classifier, 'model_ls.joblib')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PythonData",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
