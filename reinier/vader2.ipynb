{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [],
   "source": [
    "import json\n",
    "import csv\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "sid = SentimentIntensityAnalyzer()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[13], line 12\u001B[0m\n\u001B[1;32m     10\u001B[0m review_id \u001B[38;5;241m=\u001B[39m row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreview_id\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     11\u001B[0m text \u001B[38;5;241m=\u001B[39m row[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m---> 12\u001B[0m sentiment_score \u001B[38;5;241m=\u001B[39m \u001B[43msid\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpolarity_scores\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreview\u001B[49m\u001B[43m)\u001B[49m[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mcompound\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[1;32m     13\u001B[0m output_row \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mreview_id\u001B[39m\u001B[38;5;124m'\u001B[39m:review_id,\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mtext\u001B[39m\u001B[38;5;124m'\u001B[39m:text, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124msentiment\u001B[39m\u001B[38;5;124m'\u001B[39m: sentiment_score, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mstars\u001B[39m\u001B[38;5;124m'\u001B[39m: stars}\n\u001B[1;32m     14\u001B[0m output_rows\u001B[38;5;241m.\u001B[39mappend(output_row)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/nltk/sentiment/vader.py:366\u001B[0m, in \u001B[0;36mSentimentIntensityAnalyzer.polarity_scores\u001B[0;34m(self, text)\u001B[0m\n\u001B[1;32m    355\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    356\u001B[0m \u001B[38;5;124;03mReturn a float for sentiment strength based on the input text.\u001B[39;00m\n\u001B[1;32m    357\u001B[0m \u001B[38;5;124;03mPositive values are positive valence, negative value are negative\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    363\u001B[0m \u001B[38;5;124;03m    matched as if it was a normal word in the sentence.\u001B[39;00m\n\u001B[1;32m    364\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    365\u001B[0m \u001B[38;5;66;03m# text, words_and_emoticons, is_cap_diff = self.preprocess(text)\u001B[39;00m\n\u001B[0;32m--> 366\u001B[0m sentitext \u001B[38;5;241m=\u001B[39m \u001B[43mSentiText\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m    367\u001B[0m \u001B[43m    \u001B[49m\u001B[43mtext\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstants\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mPUNC_LIST\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconstants\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mREGEX_REMOVE_PUNCTUATION\u001B[49m\n\u001B[1;32m    368\u001B[0m \u001B[43m\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    369\u001B[0m sentiments \u001B[38;5;241m=\u001B[39m []\n\u001B[1;32m    370\u001B[0m words_and_emoticons \u001B[38;5;241m=\u001B[39m sentitext\u001B[38;5;241m.\u001B[39mwords_and_emoticons\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/nltk/sentiment/vader.py:274\u001B[0m, in \u001B[0;36mSentiText.__init__\u001B[0;34m(self, text, punc_list, regex_remove_punctuation)\u001B[0m\n\u001B[1;32m    272\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mPUNC_LIST \u001B[38;5;241m=\u001B[39m punc_list\n\u001B[1;32m    273\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mREGEX_REMOVE_PUNCTUATION \u001B[38;5;241m=\u001B[39m regex_remove_punctuation\n\u001B[0;32m--> 274\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwords_and_emoticons \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_words_and_emoticons\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    275\u001B[0m \u001B[38;5;66;03m# doesn't separate words from\u001B[39;00m\n\u001B[1;32m    276\u001B[0m \u001B[38;5;66;03m# adjacent punctuation (keeps emoticons & contractions)\u001B[39;00m\n\u001B[1;32m    277\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mis_cap_diff \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mallcap_differential(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mwords_and_emoticons)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/nltk/sentiment/vader.py:306\u001B[0m, in \u001B[0;36mSentiText._words_and_emoticons\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    300\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    301\u001B[0m \u001B[38;5;124;03mRemoves leading and trailing puncutation\u001B[39;00m\n\u001B[1;32m    302\u001B[0m \u001B[38;5;124;03mLeaves contractions and most emoticons\u001B[39;00m\n\u001B[1;32m    303\u001B[0m \u001B[38;5;124;03m    Does not preserve punc-plus-letter emoticons (e.g. :D)\u001B[39;00m\n\u001B[1;32m    304\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    305\u001B[0m wes \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtext\u001B[38;5;241m.\u001B[39msplit()\n\u001B[0;32m--> 306\u001B[0m words_punc_dict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_words_plus_punc\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    307\u001B[0m wes \u001B[38;5;241m=\u001B[39m [we \u001B[38;5;28;01mfor\u001B[39;00m we \u001B[38;5;129;01min\u001B[39;00m wes \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(we) \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m1\u001B[39m]\n\u001B[1;32m    308\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m i, we \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28menumerate\u001B[39m(wes):\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/nltk/sentiment/vader.py:294\u001B[0m, in \u001B[0;36mSentiText._words_plus_punc\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;66;03m# the product gives ('cat', ',') and (',', 'cat')\u001B[39;00m\n\u001B[1;32m    293\u001B[0m punc_before \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(p): p[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m product(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mPUNC_LIST, words_only)}\n\u001B[0;32m--> 294\u001B[0m punc_after \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(p): p[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m product(words_only, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mPUNC_LIST)}\n\u001B[1;32m    295\u001B[0m words_punc_dict \u001B[38;5;241m=\u001B[39m punc_before\n\u001B[1;32m    296\u001B[0m words_punc_dict\u001B[38;5;241m.\u001B[39mupdate(punc_after)\n",
      "File \u001B[0;32m~/miniconda3/lib/python3.10/site-packages/nltk/sentiment/vader.py:294\u001B[0m, in \u001B[0;36m<dictcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    292\u001B[0m \u001B[38;5;66;03m# the product gives ('cat', ',') and (',', 'cat')\u001B[39;00m\n\u001B[1;32m    293\u001B[0m punc_before \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;241m.\u001B[39mjoin(p): p[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m product(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mPUNC_LIST, words_only)}\n\u001B[0;32m--> 294\u001B[0m punc_after \u001B[38;5;241m=\u001B[39m {\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mjoin\u001B[49m\u001B[43m(\u001B[49m\u001B[43mp\u001B[49m\u001B[43m)\u001B[49m: p[\u001B[38;5;241m0\u001B[39m] \u001B[38;5;28;01mfor\u001B[39;00m p \u001B[38;5;129;01min\u001B[39;00m product(words_only, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mPUNC_LIST)}\n\u001B[1;32m    295\u001B[0m words_punc_dict \u001B[38;5;241m=\u001B[39m punc_before\n\u001B[1;32m    296\u001B[0m words_punc_dict\u001B[38;5;241m.\u001B[39mupdate(punc_after)\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "# run the vader analysis and output the compound score (-1 to 1)\n",
    "count = 0\n",
    "output_rows = []\n",
    "with open('reviews_restaurants.csv', 'r') as file:\n",
    "    reader = csv.DictReader(file)\n",
    "\n",
    "    for row in reader:\n",
    "        review = row['text']\n",
    "        stars = row['stars']\n",
    "        review_id = row['review_id']\n",
    "        text = row['text']\n",
    "        sentiment_score = sid.polarity_scores(review)['compound']\n",
    "        output_row = {'review_id':review_id,'text':text, 'sentiment': sentiment_score, 'stars': stars}\n",
    "        output_rows.append(output_row)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "output_df = pd.DataFrame(output_rows)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# drop na and change dtype stars to integer\n",
    "output_df = output_df.dropna()\n",
    "output_df['stars'] = output_df['stars'].str.slice(0,1)\n",
    "output_df['stars'] = output_df['stars'].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [],
   "source": [
    "# create dataframes for various ranges in vader score\n",
    "n_one_staradj= output_df.loc[(output_df['sentiment'] >= -1) & (output_df['sentiment'] <= -0.3), ['review_id','text','sentiment','stars']]\n",
    "\n",
    "n_two_staradj = output_df.loc[(output_df['sentiment'] >= -0.5) & (output_df['sentiment'] <= 0.3), ['review_id','text','sentiment','stars']]\n",
    "\n",
    "n_three_staradj = output_df.loc[(output_df['sentiment'] >= 0.3) & (output_df['sentiment'] <= 0.75),['review_id','text','sentiment','stars']]\n",
    "\n",
    "n_four_staradj = output_df.loc[(output_df['sentiment'] >= 0.75) & (output_df['sentiment'] <= 0.95), ['review_id','text','sentiment','stars']]\n",
    "\n",
    "n_five_staradj = output_df.loc[(output_df['sentiment'] >= 0.95) & (output_df['sentiment'] <= 1), ['review_id','text','sentiment','stars']]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "outputs": [],
   "source": [
    "# add newstar column to the dataframes and merge\n",
    "n_one_staradj['newstar']= 1\n",
    "n_two_staradj['newstar']= 2\n",
    "n_three_staradj['newstar']= 3\n",
    "n_four_staradj['newstar']= 4\n",
    "n_five_staradj['newstar']= 5\n",
    "\n",
    "newstar_df = pd.concat([n_one_staradj, n_two_staradj, n_three_staradj, n_four_staradj, n_five_staradj], axis=0)\n",
    "newstar_df = newstar_df.set_index('review_id')\n",
    "newstar_df = newstar_df[~newstar_df.index.duplicated(keep='first')]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "outputs": [],
   "source": [
    "newstar_df.to_csv('data/vader_newstar_df.csv')\n",
    "newstar_df.to_json('data/vader_newstar_df.json')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
