{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from joblib import load\n",
    "# from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "ename": "NotFittedError",
     "evalue": "Vocabulary not fitted or provided",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNotFittedError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[8], line 4\u001B[0m\n\u001B[1;32m      2\u001B[0m vectorizer \u001B[38;5;241m=\u001B[39m CountVectorizer()\n\u001B[1;32m      3\u001B[0m sample_text \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThis is a positive review where the food was fantastic and the service was amazing\u001B[39m\u001B[38;5;124m'\u001B[39m\n\u001B[0;32m----> 4\u001B[0m sample_text_vect \u001B[38;5;241m=\u001B[39m \u001B[43mvectorizer\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43m[\u001B[49m\u001B[43msample_text\u001B[49m\u001B[43m]\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m sentiment_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(sample_text_vect)[\u001B[38;5;241m0\u001B[39m]\n\u001B[1;32m      6\u001B[0m sentiment_label \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mnegative\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mneutral\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mpositive\u001B[39m\u001B[38;5;124m'\u001B[39m][sentiment_pred]\n",
      "File \u001B[0;32m~/miniconda3/envs/python31/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1430\u001B[0m, in \u001B[0;36mCountVectorizer.transform\u001B[0;34m(self, raw_documents)\u001B[0m\n\u001B[1;32m   1426\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(raw_documents, \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m   1427\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1428\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIterable over raw text documents expected, string object received.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1429\u001B[0m     )\n\u001B[0;32m-> 1430\u001B[0m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_vocabulary\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1432\u001B[0m \u001B[38;5;66;03m# use the same matrix-building strategy as fit_transform\u001B[39;00m\n\u001B[1;32m   1433\u001B[0m _, X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_count_vocab(raw_documents, fixed_vocab\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m)\n",
      "File \u001B[0;32m~/miniconda3/envs/python31/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:510\u001B[0m, in \u001B[0;36m_VectorizerMixin._check_vocabulary\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    508\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_vocabulary()\n\u001B[1;32m    509\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mfixed_vocabulary_:\n\u001B[0;32m--> 510\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m NotFittedError(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVocabulary not fitted or provided\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    512\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocabulary_) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    513\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mVocabulary is empty\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n",
      "\u001B[0;31mNotFittedError\u001B[0m: Vocabulary not fitted or provided"
     ]
    }
   ],
   "source": [
    "\n",
    "model = load('model_LR.joblib')\n",
    "vectorizer = CountVectorizer()\n",
    "sample_text = 'This is a positive review where the food was fantastic and the service was amazing'\n",
    "sample_text_vect = vectorizer.transform([sample_text])\n",
    "sentiment_pred = model.predict(sample_text_vect)[0]\n",
    "sentiment_label = ['negative', 'neutral', 'positive'][sentiment_pred]\n",
    "print(f'Sentiment prediction for sample text: {sentiment_label}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "X has 229 features, but LinearSVC is expecting 963049 features as input.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[7], line 19\u001B[0m\n\u001B[1;32m     16\u001B[0m vectors \u001B[38;5;241m=\u001B[39m vectoriser\u001B[38;5;241m.\u001B[39mfit_transform([new_text])\n\u001B[1;32m     18\u001B[0m \u001B[38;5;66;03m# Use the classifier to predict the sentiment of the new text\u001B[39;00m\n\u001B[0;32m---> 19\u001B[0m prediction \u001B[38;5;241m=\u001B[39m \u001B[43mclassifier\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mvectors\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     21\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mThe predicted sentiment of the new text is: \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mprediction[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m'\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/python31/lib/python3.10/site-packages/sklearn/linear_model/_base.py:419\u001B[0m, in \u001B[0;36mLinearClassifierMixin.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    405\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    406\u001B[0m \u001B[38;5;124;03mPredict class labels for samples in X.\u001B[39;00m\n\u001B[1;32m    407\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    416\u001B[0m \u001B[38;5;124;03m    Vector containing the class labels for each sample.\u001B[39;00m\n\u001B[1;32m    417\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    418\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[0;32m--> 419\u001B[0m scores \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecision_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    420\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(scores\u001B[38;5;241m.\u001B[39mshape) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n\u001B[1;32m    421\u001B[0m     indices \u001B[38;5;241m=\u001B[39m xp\u001B[38;5;241m.\u001B[39mastype(scores \u001B[38;5;241m>\u001B[39m \u001B[38;5;241m0\u001B[39m, \u001B[38;5;28mint\u001B[39m)\n",
      "File \u001B[0;32m~/miniconda3/envs/python31/lib/python3.10/site-packages/sklearn/linear_model/_base.py:400\u001B[0m, in \u001B[0;36mLinearClassifierMixin.decision_function\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    397\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m)\n\u001B[1;32m    398\u001B[0m xp, _ \u001B[38;5;241m=\u001B[39m get_namespace(X)\n\u001B[0;32m--> 400\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\u001B[43m)\u001B[49m\n\u001B[1;32m    401\u001B[0m scores \u001B[38;5;241m=\u001B[39m safe_sparse_dot(X, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoef_\u001B[38;5;241m.\u001B[39mT, dense_output\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mTrue\u001B[39;00m) \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mintercept_\n\u001B[1;32m    402\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m xp\u001B[38;5;241m.\u001B[39mreshape(scores, \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m1\u001B[39m) \u001B[38;5;28;01mif\u001B[39;00m scores\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m scores\n",
      "File \u001B[0;32m~/miniconda3/envs/python31/lib/python3.10/site-packages/sklearn/base.py:588\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, **check_params)\u001B[0m\n\u001B[1;32m    585\u001B[0m     out \u001B[38;5;241m=\u001B[39m X, y\n\u001B[1;32m    587\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m no_val_X \u001B[38;5;129;01mand\u001B[39;00m check_params\u001B[38;5;241m.\u001B[39mget(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mensure_2d\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[38;5;28;01mTrue\u001B[39;00m):\n\u001B[0;32m--> 588\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_n_features\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    590\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m out\n",
      "File \u001B[0;32m~/miniconda3/envs/python31/lib/python3.10/site-packages/sklearn/base.py:389\u001B[0m, in \u001B[0;36mBaseEstimator._check_n_features\u001B[0;34m(self, X, reset)\u001B[0m\n\u001B[1;32m    386\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m\n\u001B[1;32m    388\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m n_features \u001B[38;5;241m!=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_:\n\u001B[0;32m--> 389\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    390\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX has \u001B[39m\u001B[38;5;132;01m{\u001B[39;00mn_features\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features, but \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    391\u001B[0m         \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mis expecting \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mn_features_in_\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m features as input.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    392\u001B[0m     )\n",
      "\u001B[0;31mValueError\u001B[0m: X has 229 features, but LinearSVC is expecting 963049 features as input."
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# Load the saved classifier\n",
    "classifier = load('model_svm.joblib')\n",
    "\n",
    "# Load your new text file\n",
    "with open('sample_review.txt', 'r') as f:\n",
    "    new_text = f.read()\n",
    "\n",
    "# Vectorize the new text using the same TfidfVectorizer used to train the classifier\n",
    "TfidfVectorizer(ngram_range=(1, 3),min_df = 5,\n",
    "                max_df = 0.8,\n",
    "                sublinear_tf = True,\n",
    "                use_idf = True)\n",
    "vectors = vectoriser.fit_transform([new_text])\n",
    "\n",
    "# Use the classifier to predict the sentiment of the new text\n",
    "prediction = classifier.predict(vectors)\n",
    "\n",
    "print(f'The predicted sentiment of the new text is: {prediction[0]}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Iterable over raw text documents expected, string object received.",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[6], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m input_vectorized \u001B[38;5;241m=\u001B[39m \u001B[43mvectoriser\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtext\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      3\u001B[0m \u001B[38;5;66;03m#get predictions\u001B[39;00m\n\u001B[1;32m      4\u001B[0m predictions \u001B[38;5;241m=\u001B[39m classifier\u001B[38;5;241m.\u001B[39mpredict(input_vectorized)\n",
      "File \u001B[0;32m~/miniconda3/envs/python31/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:2157\u001B[0m, in \u001B[0;36mTfidfVectorizer.transform\u001B[0;34m(self, raw_documents)\u001B[0m\n\u001B[1;32m   2140\u001B[0m \u001B[38;5;124;03m\"\"\"Transform documents to document-term matrix.\u001B[39;00m\n\u001B[1;32m   2141\u001B[0m \n\u001B[1;32m   2142\u001B[0m \u001B[38;5;124;03mUses the vocabulary and document frequencies (df) learned by fit (or\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   2153\u001B[0m \u001B[38;5;124;03m    Tf-idf-weighted document-term matrix.\u001B[39;00m\n\u001B[1;32m   2154\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   2155\u001B[0m check_is_fitted(\u001B[38;5;28mself\u001B[39m, msg\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThe TF-IDF vectorizer is not fitted\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[0;32m-> 2157\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43msuper\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mtransform\u001B[49m\u001B[43m(\u001B[49m\u001B[43mraw_documents\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   2158\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_tfidf\u001B[38;5;241m.\u001B[39mtransform(X, copy\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n",
      "File \u001B[0;32m~/miniconda3/envs/python31/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:1427\u001B[0m, in \u001B[0;36mCountVectorizer.transform\u001B[0;34m(self, raw_documents)\u001B[0m\n\u001B[1;32m   1411\u001B[0m \u001B[38;5;124;03m\"\"\"Transform documents to document-term matrix.\u001B[39;00m\n\u001B[1;32m   1412\u001B[0m \n\u001B[1;32m   1413\u001B[0m \u001B[38;5;124;03mExtract token counts out of raw text documents using the vocabulary\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1424\u001B[0m \u001B[38;5;124;03m    Document-term matrix.\u001B[39;00m\n\u001B[1;32m   1425\u001B[0m \u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   1426\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(raw_documents, \u001B[38;5;28mstr\u001B[39m):\n\u001B[0;32m-> 1427\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m   1428\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mIterable over raw text documents expected, string object received.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m   1429\u001B[0m     )\n\u001B[1;32m   1430\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_check_vocabulary()\n\u001B[1;32m   1432\u001B[0m \u001B[38;5;66;03m# use the same matrix-building strategy as fit_transform\u001B[39;00m\n",
      "\u001B[0;31mValueError\u001B[0m: Iterable over raw text documents expected, string object received."
     ]
    }
   ],
   "source": [
    "input_vectorized = vectoriser.transform(text)\n",
    "\n",
    "#get predictions\n",
    "predictions = classifier.predict(input_vectorized)\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentiment prediction for test text: positive\n"
     ]
    }
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Load the saved model and CountVectorizer using joblib\n",
    "model = joblib.load('model_LR.joblib')\n",
    "vectorizer = joblib.load('vectorizer_LR.joblib')\n",
    "\n",
    "# Load the test text from a file\n",
    "with open('sample_review.txt', 'r') as f:\n",
    "    test_text = f.read()\n",
    "\n",
    "# Transform the test text into numerical features using the CountVectorizer\n",
    "test_text_vect = vectorizer.transform([test_text])\n",
    "\n",
    "# Predict the sentiment of the test text using the loaded model\n",
    "sentiment_pred = model.predict(test_text_vect)[0]\n",
    "sentiment_label = ['negative', 'neutral', 'positive'][sentiment_pred]\n",
    "print(f'Sentiment prediction for test text: {sentiment_label}')"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
